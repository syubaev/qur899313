{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8acc802-80ba-e4b0-403c-df40ce20cf20"
   },
   "source": [
    "# Visualizing Word Vectors with t-SNE\n",
    "\n",
    "TSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. \n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Load cleaned data\n",
    "2. Build a corpus\n",
    "3. Train a Word2Vec Model\n",
    "4. Train XGBoost and logReg\n",
    "\n",
    "Credit: Some of the code was inspired by this awesome [NLP repo][1]. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  [1]: https://github.com/rouseguy/DeepLearningNLP_Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "327a2a48-c101-959c-af2d-cabd82276e65",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "import re\n",
    "#import nltk\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (16,6)\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 s, sys: 628 ms, total: 6.38 s\n",
      "Wall time: 9.99 s\n",
      "time: 9.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data = pd.read_csv('data/train.csv').sample(50000, random_state=23)\n",
    "train = pd.read_csv('../data/train_wo_sw.csv')\n",
    "train = train.drop(train.columns[0], axis=1)\n",
    "\n",
    "test = pd.read_csv('../data/test_wo_sw.csv')\n",
    "test = test.drop(test.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 569 ms\n"
     ]
    }
   ],
   "source": [
    "for data in [train, test]:\n",
    "    for col in ['question1', 'question2']:\n",
    "        data[col][pd.isnull(data[col])] = ''\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.91 ms\n"
     ]
    }
   ],
   "source": [
    "assert 2345796 == test.shape[0]\n",
    "assert 404290 == train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6) (2345796, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>one coin</td>\n",
       "      <td>whats coin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>approx annual cost living studying uic chicago...</td>\n",
       "      <td>little hairfall problem use hair styling produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>like sex cousin</td>\n",
       "      <td>like sex cousin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "404287                                           one coin   \n",
       "404288  approx annual cost living studying uic chicago...   \n",
       "404289                                    like sex cousin   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "404287                                         whats coin             0  \n",
       "404288  little hairfall problem use hair styling produ...             0  \n",
       "404289                                    like sex cousin             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.8 ms\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head(3)\n",
    "train.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>surface pro 4 compare ipad pro</td>\n",
       "      <td>microsoft choose core m3 core i3 home surface ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hair transplant age 24 much would cost</td>\n",
       "      <td>much cost hair transplant require</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>best way send money china us</td>\n",
       "      <td>send money china</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                               question1  \\\n",
       "0        0          surface pro 4 compare ipad pro   \n",
       "1        1  hair transplant age 24 much would cost   \n",
       "2        2            best way send money china us   \n",
       "\n",
       "                                           question2  \n",
       "0  microsoft choose core m3 core i3 home surface ...  \n",
       "1                  much cost hair transplant require  \n",
       "2                                   send money china  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9 ms\n"
     ]
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e72326d7-e707-d4e9-928a-519a9193bfc5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "def build_corpus(data):\n",
    "    \"Creates a list of lists containing words from each sentence\"\n",
    "    corpus = []\n",
    "    for col in ['question1', 'question2']:\n",
    "        for sentence in data[col].iteritems():\n",
    "            try:\n",
    "                word_list = sentence[1].split()\n",
    "            except:\n",
    "                print(col, sentence)\n",
    "                raise\n",
    "            corpus.append(word_list)\n",
    "            \n",
    "    return corpus\n",
    "\n",
    "corpus = build_corpus(pd.concat([train, test]))       \n",
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(corpus) == (train.shape[0] + test.shape[0])*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c652ad03-be65-f4e6-0afd-02c237449b43"
   },
   "source": [
    "# Word 2 Vec\n",
    "\n",
    "The Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_w2v = word2vec.Word2Vec(corpus, size=100, window=20, min_count=1, workers=4)\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "#model_w2v.save(\"../data/word2vec.model\")\n",
    "model_w2v = word2vec.Word2Vec.load(\"../data/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.64 ms\n"
     ]
    }
   ],
   "source": [
    "model_w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.21 ms\n"
     ]
    }
   ],
   "source": [
    "def auc_plot(y_true, y_pred):\n",
    "    loss = metrics.log_loss(y_true, y_pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    roc_auc=metrics.auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return loss, roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 µs\n",
      "time: 47.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def calc_cosine_similir(q1, q2):\n",
    "    if len(q1) == 0 or len(q2) ==0:\n",
    "        return 0\n",
    "    v1 = np.sum([model_w2v.wv[w] for w in q1], axis = 0)\n",
    "    v2 = np.sum([model_w2v.wv[w] for w in q2], axis = 0)\n",
    "    res = np.dot(v1, v2) / ( np.sqrt(np.dot(v1, v1)) * np.sqrt(np.dot(v2, v2)) )\n",
    "    if type(res) != np.dtype('float32'):\n",
    "        print(type(res))\n",
    "        print(q1,q2,v1,v2)\n",
    "        raise\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_counters_from_list(l):\n",
    "    n = len(l)\n",
    "    if n == 0:\n",
    "        return [0.0] * 10\n",
    "    l = [np.sum(l),\n",
    "         np.min(l),\n",
    "         np.max(l),\n",
    "         np.median(l),\n",
    "         np.average(l)]\n",
    "    return l + [x/n for x in l]\n",
    "    \n",
    "    \n",
    "def calc_w2v_similarity(row):\n",
    "    q1 = row['question1'].split() \n",
    "    q2 = row['question2'].split()\n",
    "    cosine_similir = calc_cosine_similir(q1, q2)\n",
    "    q1_uniq = list(set(q1) - set(q2)) \n",
    "    q2_uniq = list(set(q2) - set(q1))\n",
    "    words_simil = []\n",
    "    for w1 in q1_uniq:    \n",
    "        for w2 in q2_uniq:\n",
    "            s = model_w2v.similarity(w1, w2)\n",
    "            words_simil.append(s)\n",
    "    feat_count = calc_counters_from_list(words_simil)\n",
    "    return [cosine_similir] + calc_counters_from_list(words_simil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.65 ms\n"
     ]
    }
   ],
   "source": [
    "def split_df_to_pools(f, data):\n",
    "    if not callable(f):\n",
    "        raise\n",
    "    try:\n",
    "        p = mp.Pool(processes=4)\n",
    "        split = np.array_split(data, 8)\n",
    "        res = p.map(f, split)\n",
    "    except:\n",
    "        raise\n",
    "    finally:\n",
    "        p.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "def f_woker(x):\n",
    "    return np.vstack(x.apply(lambda row: calc_w2v_similarity(row), axis=1))\n",
    "# X_w2v = np.vstack(f_woker(train))\n",
    "X_w2v = np.vstack(split_df_to_pools(f_woker, train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17min 10s\n"
     ]
    }
   ],
   "source": [
    "X_w2v_test = np.vstack(split_df_to_pools(f_woker, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.34 ms\n"
     ]
    }
   ],
   "source": [
    "def calc_common_len_ratio(list1, list2):\n",
    "    \"\"\"Calculate number of common elements in lists.\n",
    "    Return list with number and ratio.\n",
    "    \"\"\"\n",
    "    common_unigrams_len = len( set(list1).intersection(set(list2)) )\n",
    "    common_unigrams_ratio = float(common_unigrams_len) / max(len( set(list1).union(set(list2)) ),1)\n",
    "    return [common_unigrams_len, common_unigrams_ratio]\n",
    "\n",
    "\n",
    "def feature_extraction(row):\n",
    "    unigrams_que1 = row['question1'].split() \n",
    "    unigrams_que2 = row['question2'].split()\n",
    "    out_list = calc_common_len_ratio(unigrams_que1, unigrams_que2)\n",
    "    \n",
    "    # get bigram and trigram features #\n",
    "    for ngr_numb in [2,3]:\n",
    "        q1_ngram = [i for i in ngrams(unigrams_que1, ngr_numb)]\n",
    "        q2_ngram = [i for i in ngrams(unigrams_que2, ngr_numb)]\n",
    "        out_list = out_list + calc_common_len_ratio(q1_ngram, q2_ngram)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:18: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "def f_woker(x):\n",
    "    return np.array(x.apply(lambda row: feature_extraction(row), axis=1, raw=True))\n",
    "X_common = np.vstack(split_df_to_pools(f_woker, train))\n",
    "X_common_test = np.vstack(f_woker(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 17), (2345796, 17))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "y = train.is_duplicate\n",
    "X = np.c_[X_common, X_w2v]; X_test = np.c_[X_common_test, X_w2v_test]\n",
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalancing the Data\n",
    "\n",
    "However, before I do this, I would like to rebalance the data that XGBoost receives, since we have 37% positive class in our training data, and only 17% in the test data. By re-balancing the data so our training set has 17% positives, we can ensure that XGBoost outputs probabilities that will better match the data on the leaderboard, and should get a better score (since LogLoss looks at the probabilities themselves and not just the order of the predictions like AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "neg_count = np.sum(y == 0)\n",
    "neg_ind_add = np.random.choice(a=neg_count, size=450000, replace=True)\n",
    "X_bal = np.concatenate((X, X[y==0][neg_ind_add,:]), axis=0) \n",
    "y_bal = np.concatenate((y, np.zeros(len(neg_ind_add))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.28 ms\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params['eval_metric'] = 'logloss'\n",
    "params[\"eta\"] = 0.01\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"min_child_weight\"] = 25\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"max_depth\"] = 6\n",
    "params[\"silent\"] = 1\n",
    "params[\"seed\"] = 42\n",
    "params['alpha'] = 0.1\n",
    "num_rounds = 800 \n",
    "plst = list(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgbcv = xgb.cv(plst, dtrain=xgtrain, num_boost_round=num_rounds, folds=kf, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xgbcv.iloc[100:,2], label='train')\n",
    "plt.plot(xgbcv.iloc[100:,0], label='test')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = xgbcv.iloc[400:,:]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.errorbar(x=400+np.arange(len(t)), y=t.iloc[:,0], yerr=t.iloc[:,1])\n",
    "plt.errorbar(x=400+np.arange(len(t)), y=t.iloc[:,2], yerr=t.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(xgbcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xgbcv.iloc[100:,2], label='train')\n",
    "plt.plot(xgbcv.iloc[100:,0], label='test')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit XGBoost cos similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14min 7s\n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(X_bal, label=y_bal)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "model = xgb.train(plst, xgtrain, num_rounds, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "xgtest = xgb.DMatrix(X_test)\n",
    "y_pred = model.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: submit_w2v_common_balance.csv\n",
      "\n",
      "zip error: Nothing to do! (submit_w2v_common_balance.csv.zip)\n",
      "time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "#fname = '../submit/submit_w2v_common_balance.csv'\n",
    "pd.DataFrame({'test_id':test.test_id, 'is_duplicate':y_pred}\n",
    "            ).to_csv('../submit/submit_w2v_common_balance.csv', index=False)\n",
    "!zip submit_w2v_common_balance.csv.zip submit_w2v_common_balance.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!zip 1submit_w2v_common_balance.csv.zip submit_w2v_common_balance.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = train.is_duplicate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=0.5,\n",
    "                   fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "                   random_state=42, solver='liblinear', max_iter=100,\n",
    "                   multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_log = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params['eval_metric'] = 'logloss'\n",
    "params[\"eta\"] = 0.02\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"min_child_weight\"] = 25\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"max_depth\"] = 4\n",
    "params[\"silent\"] = 1\n",
    "params[\"seed\"] = 42\n",
    "num_rounds = 1000 \n",
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "xgtest = xgb.DMatrix(X_test, label=y_test)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "model = xgb.train(plst, xgtrain, num_rounds, watchlist,\n",
    "                  early_stopping_rounds=25, verbose_eval=50)\n",
    "y_pred = model.predict(xgtest)\n",
    "auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(xgtest)\n",
    "auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(model,  title=coef_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_plot(y_test, (y_pred + y_pred_log)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1.shape[0] - test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
